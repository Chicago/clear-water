{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import read_data as rd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import visualizations as viz\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions\n",
    "\n",
    "These are used throughout the rest of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prev_nday(df, target, n=1, mean_window=7):\n",
    "    min_yr = df.Date.dt.year.min()\n",
    "    max_yr = df.Date.dt.year.max()\n",
    "    yr_range = range(min_yr, max_yr+1)\n",
    "    \n",
    "    prev_df = pd.concat([df[df.Date.dt.year == year].groupby('Beach')\\\n",
    "                         .apply(lambda x: x.set_index('Date').resample('D').asfreq())\\\n",
    "                         .drop('Beach', axis=1).reset_index()\n",
    "                         for year in yr_range])\n",
    "    \n",
    "    if isinstance(target, str):\n",
    "        target = [target, ]\n",
    "    \n",
    "    prev_target = [str(n)+ '_prev_' + key for key in target]\n",
    "    prev_df[prev_target] = prev_df.groupby(['Beach', prev_df.Date.dt.year]).shift()[target]\n",
    "    prev_df.drop(target, axis=1, inplace=True)\n",
    "    \n",
    "    means = prev_df.groupby(['Beach', prev_df.Date.dt.year])[prev_target]\\\n",
    "                   .transform(lambda x: x.rolling(min_periods=1, center=False, window=mean_window).mean())\n",
    "    \n",
    "    prev_df[prev_target] = prev_df[prev_target].fillna(means)\n",
    "    \n",
    "    for yr in yr_range:\n",
    "        means = prev_df[prev_df.Date.dt.year != yr].mean()\n",
    "        prev_df.loc[prev_df.Date.dt.year == yr, prev_target] =\\\n",
    "        prev_df.loc[prev_df.Date.dt.year == yr, prev_target].fillna(means)\n",
    "        \n",
    "    \n",
    "    return prev_df  \n",
    "\n",
    "def run_model(df, model, predictors, target='Escherichia.coli', threshold=235, yrs=range(2006,2015)):\n",
    "    \n",
    "    model_df = df[['Date', target] + predictors].copy().dropna()\n",
    "    \n",
    "    for predictor in predictors:\n",
    "        if model_df[predictor].dtype == 'object':\n",
    "            model_df[predictor] = pd.Categorical(model_df[predictor]).codes\n",
    "    \n",
    "    fits = {}\n",
    "    for yr in yrs:\n",
    "        model = sklearn.base.clone(model) \n",
    "        train = model_df[model_df.Date.dt.year != yr][predictors]\n",
    "        classes = model_df[model_df.Date.dt.year != yr][target] > threshold\n",
    "        \n",
    "        fits[yr] = model.fit(train, classes)\n",
    "        \n",
    "    return fits, model_df\n",
    "        \n",
    "def calc_metrics(model_df, predictors, fits, metrics=[], \n",
    "                 target='Escherichia.coli', threshold=235, gen_avg=False):\n",
    "    \n",
    "    calced_metrics = {}\n",
    "    avg_calced_metrics = {}\n",
    "    for metric in metrics:\n",
    "        yr_scores = {}\n",
    "        \n",
    "        for yr, fit in fits.items():\n",
    "            test = model_df[model_df.Date.dt.year == yr][predictors]\n",
    "            true_classes = model_df[model_df.Date.dt.year == yr][target] > threshold\n",
    "            \n",
    "            if 'roc' in metric:\n",
    "                preds = fit.predict_proba(test)[:,1]\n",
    "            else:\n",
    "                preds = fit.predict(test)\n",
    "        \n",
    "            yr_scores[yr] = getattr(sklearn.metrics, metric)(true_classes, preds)\n",
    "        \n",
    "        calced_metrics[metric] = yr_scores\n",
    "        if gen_avg:\n",
    "            try:\n",
    "                avg_calced_metrics[metric] = np.array(list(calced_metrics[metric].values()))\\\n",
    "                                               .mean(axis=0)\n",
    "            except ValueError: \n",
    "                print(\"Can't average %s\" %metric)\n",
    "                \n",
    "    return (calced_metrics, avg_calced_metrics) if gen_avg else calced_metrics\n",
    "\n",
    "def plot_roc(roc_dict, drek_df, roc_aucs=None):\n",
    "    colors = itertools.cycle(sns.color_palette('colorblind', 6))\n",
    "    \n",
    "    for yr, arrays in metrics['roc_curve'].items():\n",
    "        if roc_aucs is not None:\n",
    "            label = str(yr) + \" - AUC: {:0.4f}\".format(roc_aucs[yr])\n",
    "        else:\n",
    "            label = yr\n",
    "        fpr = arrays[0]\n",
    "        tpr = arrays[1]\n",
    "        if yr <= 2010:\n",
    "            plt.plot(fpr, tpr, label=label, color=next(colors))\n",
    "        else:\n",
    "            plt.plot(fpr, tpr, '--', label=label, color=next(colors))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'r:')\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(drek_df['Escherichia.coli'] > 235, \n",
    "                                            drek_df['Drek_Prediction'])\n",
    "    \n",
    "    if roc_aucs is not None:\n",
    "        drek_auc = sklearn.metrics.roc_auc_score(drek_df['Escherichia.coli'] > 235, \n",
    "                                                 drek_df['Drek_Prediction'])\n",
    "        label = 'Drek - AUC: {:0.4f}'.format(drek_auc)\n",
    "    else:\n",
    "        label = 'Drek'\n",
    "        \n",
    "    plt.plot(fpr, tpr, 'k--', lw=2, label=label)\n",
    "\n",
    "    plt.legend(loc='lower right', fontsize=12)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def get_feat_df(fits, predictors):\n",
    "    vals = [[yr, feat, imp] for yr, fit in fits.items() \n",
    "            for feat, imp in zip(predictors, fit.feature_importances_)] \n",
    "    \n",
    "    return pd.DataFrame(vals, columns = ['Year', 'Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_df = rd.read_data(read_drek=True, read_holiday=False, read_weather_station=False,\n",
    "                        read_water_sensor=False, read_daily_forecast=False, read_hourly_forecast=False,\n",
    "                        group_beaches=False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drek_df = clean_df[['Drek_Prediction', 'Escherichia.coli']].copy().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = clean_df.copy()\n",
    "df.drop(['Reading.1', 'Reading.2', 'Units', 'Sample.Collection.Time', \n",
    "         'Date', 'Laboratory.ID', 'Weekday', 'Beach', 'Year',\n",
    "         'Drek_Reading', 'Drek_Prediction', 'Drek_Worst_Swim_Status'], axis=1, inplace=True)\n",
    "df = df[~df['Escherichia.coli'].isnull()]\n",
    "df.rename(columns={'Full_date': 'Date', 'Client.ID': 'Beach'}, inplace=True)\n",
    "\n",
    "cleannames_file = '../data/ChicagoParkDistrict/raw/Standard 18 hr Testing/cleanbeachnames.csv'\n",
    "with open(cleannames_file) as f:\n",
    "    next(f)\n",
    "    cleannames_dict = {line[1]: line[3] for line in csv.reader(f)}\n",
    "    \n",
    "df.Beach.replace(cleannames_dict, inplace=True)\n",
    "\n",
    "df = df[~df.duplicated(subset=['Date', 'Beach'])]\n",
    "\n",
    "#we're just looking at years 2006-2014 for now\n",
    "df = df[df.Date.dt.year < 2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df for lat & lon for each beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beach_locs = pd.read_csv('../data/ExternalData/Beach_Locations.csv')\n",
    "beach_locs.Beach.replace(cleannames_dict, inplace=True)\n",
    "beach_locs = beach_locs.groupby('Beach').mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast.io data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forecast = pd.read_csv('../data/ExternalData/forecastio_daily_weather.csv')\n",
    "forecast.time = pd.to_datetime(forecast.time)\n",
    "forecast.rename(columns={'time': 'Date', 'beach': 'Beach'}, inplace=True)\n",
    "forecast.Beach.replace(cleannames_dict, inplace=True)\n",
    "forecast = forecast[~forecast.duplicated(subset=['Date', 'Beach'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hourly forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hr_forecast = pd.read_csv('../data/ExternalData/forecastio_hourly_weather.csv')\n",
    "hr_forecast.time = pd.to_datetime(hr_forecast.time)\n",
    "hr_forecast.rename(columns={'time': 'Date', 'beach': 'Beach'}, inplace=True)\n",
    "hr_forecast.Beach.replace(cleannames_dict, inplace=True)\n",
    "hr_forecast = hr_forecast[~hr_forecast.duplicated(subset=['Date', 'Beach'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Current Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-specific data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_df = df.copy()\n",
    "\n",
    "#Add columns for 1 through 7 previous day ecoli readings\n",
    "prev_days = [get_prev_nday(rf_df, 'Escherichia.coli', i) for i in range(1, 8)]\n",
    "for prev_df in prev_days:\n",
    "    rf_df = pd.merge(rf_df, prev_df, on=['Date', 'Beach'])\n",
    "\n",
    "#Get historical average across those 7 days\n",
    "prev_cols = [col for col in rf_df.columns if 'prev' in col]\n",
    "rf_df['historical_average_Escherichia.coli'] = rf_df[prev_cols].mean(axis=1)\n",
    "\n",
    "#Add in historical averages for daily forecast of temperatureMin and temperatureMax\n",
    "rf_forecast = forecast.copy()\n",
    "rf_forecast = rf_forecast.sort_values(by=['Beach', 'Date'])\n",
    "rf_forecast['historical_average_temperatureMin'] =\\\n",
    "         rf_forecast.groupby(['Beach', rf_forecast.Date.dt.year])['temperatureMin']\\\n",
    "                  .apply(lambda x: x.rolling(min_periods=1, center=False, window=3).mean())\n",
    "        \n",
    "rf_forecast['historical_average_temperatureMax'] =\\\n",
    "         rf_forecast.groupby(['Beach', rf_forecast.Date.dt.year])['temperatureMax']\\\n",
    "                  .apply(lambda x: x.rolling(min_periods=1, center=False, window=3).mean())\n",
    "        \n",
    "#Separate hourly data into multiple columns, add previous day columns as well\n",
    "rf_hr = hr_forecast.copy()\n",
    "col_list = ['Date', 'Beach']+[col for col in rf_hr.columns \n",
    "                              if col != 'Date' and col != 'Beach' and col != 'precipType']\n",
    "rf_hr = rf_hr[col_list]\n",
    "rf_hr = rf_hr.sort_values(by='Date').reset_index(drop=True)\n",
    "rf_hr = rf_hr.groupby('Beach').apply(pd.Series.interpolate)\n",
    "\n",
    "df_list = []\n",
    "for time in range(24):\n",
    "    subhr_df = rf_hr[rf_hr.Date.dt.hour == time]\\\n",
    "                    [col_list].reset_index(drop=True)\n",
    "    prefix = 'hr' + str(time) + '_'\n",
    "    subhr_df.columns = col_list[:2] + [prefix + col \n",
    "                                       for col in col_list[2:]]\n",
    "    subhr_df.Date = pd.DatetimeIndex(subhr_df.Date).normalize()\n",
    "    subhr_df[prefix + 'summary'] = pd.Categorical(subhr_df[prefix + 'summary']).codes\n",
    "    subhr_df[prefix + 'icon'] = pd.Categorical(subhr_df[prefix + 'icon']).codes\n",
    "    \n",
    "    df_list.append(subhr_df)\n",
    "    \n",
    "multi_hr = df_list[0]\n",
    "for hr_df in df_list[1:]:\n",
    "    multi_hr = pd.merge(multi_hr, hr_df, on=['Date', 'Beach'])\n",
    "    \n",
    "target = multi_hr.columns.tolist()[2:]\n",
    "multi_hr = pd.merge(multi_hr, get_prev_nday(multi_hr, target, 1), on=['Date', 'Beach'])\n",
    "\n",
    "#put it all together\n",
    "rf_df = pd.merge(rf_df, multi_hr, on=['Beach', 'Date'])\n",
    "rf_df = pd.merge(rf_df, rf_forecast, on=['Beach', 'Date'])\n",
    "rf_df = pd.merge(rf_df, beach_locs, on=['Beach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc other feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navy_pier = 41.8916\n",
    "rf_df['n_pier'] = rf_df.Latitude > navy_pier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = ['1_prev_hr13_temperature', 'precipIntensityMax', '1_prev_hr8_temperature',\n",
    "              'hr1_windBearing', 'cloudCover', '1_prev_hr11_temperature', 'windSpeed', \n",
    "              'hr3_windBearing', 'hr2_windBearing', 'hr2_cloudCover', '1_prev_hr15_temperature',\n",
    "              'humidity', 'hr4_windBearing', 'hr3_windSpeed', '1_prev_hr21_temperature', 'hr4_cloudCover',\n",
    "              'hr4_windSpeed', '1_prev_hr12_temperature', 'hr0_temperature', 'hr0_pressure', 'precipIntensity', \n",
    "              'hr2_windSpeed', 'sunriseTime', 'temperatureMin', 'hr1_windSpeed', 'hr0_cloudCover', \n",
    "              '1_prev_Escherichia.coli', '2_prev_Escherichia.coli', '3_prev_Escherichia.coli',\n",
    "              '4_prev_Escherichia.coli', '5_prev_Escherichia.coli', '6_prev_Escherichia.coli',\n",
    "              '7_prev_Escherichia.coli', 'n_pier', 'historical_average_Escherichia.coli'\n",
    "             ]\n",
    "model = RandomForestClassifier(n_estimators=2000, max_depth=6, n_jobs=-1, class_weight={0: 1.0, 1: 1/.15})\n",
    "fits, model_df = run_model(rf_df, model, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics = calc_metrics(model_df, predictors, fits, \n",
    "                       metrics=['roc_curve', 'roc_auc_score'])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plot_roc(metrics['roc_curve'], drek_df, metrics['roc_auc_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_feat_df(fits, predictors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
